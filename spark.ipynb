{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eed989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as Func\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f841887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('_c0', StringType(), True), StructField('order_id', StringType(), True), StructField('order_item_id', StringType(), True), StructField('customer_id', StringType(), True), StructField('customer_unique_id', StringType(), True), StructField('customer_zip_code_prefix', StringType(), True), StructField('customer_city', StringType(), True), StructField('customer_state', StringType(), True), StructField('product_id', StringType(), True), StructField('product_category_name', StringType(), True), StructField('product_name_lenght', StringType(), True), StructField('product_description_lenght', StringType(), True), StructField('product_photos_qty', StringType(), True), StructField('product_weight_g', StringType(), True), StructField('product_length_cm', StringType(), True), StructField('product_height_cm', StringType(), True), StructField('product_width_cm', StringType(), True), StructField('seller_id', StringType(), True), StructField('seller_city', StringType(), True), StructField('seller_state', StringType(), True), StructField('seller_zip_code_prefix', StringType(), True), StructField('payment_type', StringType(), True), StructField('payment_sequential', StringType(), True), StructField('payment_installments', StringType(), True), StructField('price', StringType(), True), StructField('freight_value', StringType(), True), StructField('payment_value', StringType(), True), StructField('shipping_limit_date', StringType(), True), StructField('order_purchase_timestamp', StringType(), True), StructField('order_approved_at', StringType(), True), StructField('order_delivered_carrier_date', StringType(), True), StructField('order_delivered_customer_date', StringType(), True), StructField('order_estimated_delivery_date', StringType(), True), StructField('day_of_purchase', StringType(), True), StructField('month_of_purchase', StringType(), True), StructField('year_of_purchase', StringType(), True), StructField('month/year_of_purchase', StringType(), True), StructField('order_status', StringType(), True), StructField('order_unique_id', StringType(), True)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo a leitura dos dados da tabela raw (Brazilian E-Commerce Public Dataset by Olist.csv)\n",
    "df = spark.read.format(\"csv\").load(\"/home/anthony/Brazilian E-Commerce Public Dataset by Olist.csv\", header = True)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbd4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos o primeiro tratamento, gerando um novo DF com as colunas que iremos trabalhar e gerar os insights\n",
    "dff = df.select(\"order_id\",\"customer_id\",\"customer_unique_id\",\"customer_city\",\"customer_state\",\"product_category_name\",\"seller_city\",\"seller_state\",\"payment_type\",\"payment_installments\",\"price\",\"freight_value\",\"payment_value\",\"order_purchase_timestamp\",\"order_approved_at\",\"day_of_purchase\",\"month_of_purchase\",\"year_of_purchase\",\"order_unique_id\")\n",
    "\n",
    "# Modificamos as colunas com data para tipo timestamp e assim conseguirmos alterar somente o ano dentro da coluna.\n",
    "dff = dff.withColumn(\"order_approved_at\", to_timestamp(Func.col(\"order_approved_at\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "dff = dff.withColumn(\"order_purchase_timestamp\", to_timestamp(Func.col(\"order_purchase_timestamp\"), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe42e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos uma função(def) para conseguir alterar o ano de 2018 para 2023\n",
    "def change_year2018(date):\n",
    "    if date.year == 2018:\n",
    "        return datetime.datetime(2023, date.month, date.day, date.hour, date.minute, date.second)\n",
    "    return date\n",
    "\n",
    "# Definimos uma função(def) para conseguir alterar o ano de 2017 para 2022\n",
    "def change_year2017(date):\n",
    "    if date.year == 2017:\n",
    "        return datetime.datetime(2022, date.month, date.day, date.hour, date.minute, date.second)\n",
    "    return date\n",
    "\n",
    "# Definimos uma função(def) para conseguir alterar o ano de 2016 para 2021\n",
    "def change_year2016(date):\n",
    "    if date.year == 2016:\n",
    "        return datetime.datetime(2021, date.month, date.day, date.hour, date.minute, date.second)\n",
    "    return date\n",
    "\n",
    "# Definido as funçes criamos as variaveis separadas de tranformação de 2018, 2017 e 2016\n",
    "change_year_udf2018 = udf(change_year2018, TimestampType())\n",
    "change_year_udf2017 = udf(change_year2017, TimestampType())\n",
    "change_year_udf2016 = udf(change_year2016, TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f324c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com o withColumn alteramos as colunas sobrescrevendo seus valores com o ano atualizado definido na funçao\n",
    "dff = dff.withColumn(\"order_approved_at\", change_year_udf2018(col(\"order_approved_at\")))\n",
    "dff = dff.withColumn(\"order_approved_at\", change_year_udf2017(col(\"order_approved_at\")))\n",
    "dff = dff.withColumn(\"order_approved_at\", change_year_udf2016(col(\"order_approved_at\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc6e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.withColumn(\"order_purchase_timestamp\", change_year_udf2018(col(\"order_purchase_timestamp\")))\n",
    "dff = dff.withColumn(\"order_purchase_timestamp\", change_year_udf2017(col(\"order_purchase_timestamp\")))\n",
    "dff = dff.withColumn(\"order_purchase_timestamp\", change_year_udf2016(col(\"order_purchase_timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5428b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos o withColumn para atualizar o ano da coluna \"year_of_purchase'\" e deixar o mesmo que as outras\n",
    "\n",
    "dff = dff.withColumn(\"year_of_purchase\", when(col(\"year_of_purchase\") == \"2018\", \"2023\").otherwise(col(\"year_of_purchase\")))\n",
    "dff = dff.withColumn(\"year_of_purchase\", when(col(\"year_of_purchase\") == \"2017\", \"2022\").otherwise(col(\"year_of_purchase\")))\n",
    "dff = dff.withColumn(\"year_of_purchase\", when(col(\"year_of_purchase\") == \"2016\", \"2021\").otherwise(col(\"year_of_purchase\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec9235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteramos a coluna \"day_of_purchase\" para o dia do ano correto, ja que o dia em 2017 e um e em 2022 e outro.\n",
    "dff = dff.withColumn(\"day_of_purchase\", date_format(col(\"order_approved_at\"), \"EEEE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237c9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteramos a formataço da coluna para / inves de -\n",
    "#dff = dff.withColumn(\"order_approved_at\", date_format(col(\"order_approved_at\"), \"yyyy/MM/dd HH:mm:ss\"))\n",
    "dff = dff.withColumn(\"order_purchase_timestamp\", date_format(col(\"order_purchase_timestamp\"), \"yyyy/MM/dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45c16a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_unique_id: string (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      " |-- product_category_name: string (nullable = true)\n",
      " |-- seller_city: string (nullable = true)\n",
      " |-- seller_state: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- payment_installments: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- freight_value: string (nullable = true)\n",
      " |-- payment_value: string (nullable = true)\n",
      " |-- order_purchase_timestamp: string (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- day_of_purchase: string (nullable = true)\n",
      " |-- month_of_purchase: string (nullable = true)\n",
      " |-- year_of_purchase: string (nullable = true)\n",
      " |-- order_unique_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# salvamos a tabela já tratada com os dados que iremos utilizar.\n",
    "dff.write.csv(\"/home/anthony/pyspark/tratamento/\", header=True)\n",
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae857e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278e5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0225e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
